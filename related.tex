\chapter{Related Work}
\label{ch:related}

The scope of this work encompasses three large areas: program synthesis, data wrangling, and active learning.
All three communities have developed numerous alternative solutions to the problems related to the ones I discuss in
this discuss.
This chapter presents an overview of related work in both areas, focusing on significant, influential, highly relevant
papers, as well as comparing and contrasting PROSE with the existing efforts.

\section{Program Synthesis}
\label{sec:related:synthesis}

In \Cref{ch:intro}, we outlined the main techniques, strengths, and weaknesses of two large families of recent
program synthesis works, \emph{syntax-guided} and \emph{domain-specific inductive synthesis}.
The PROSE framework is our contribution to unifying the strengths of both approaches into a single system.
It follows the recent line of effort in standardizing the program synthesis space and developing generic synthesis
strategies and frameworks.
Apart from PROSE, three main initiatives in this space are \textsc{Sketch}~\cite{sketch},
\textsc{Rosette}~\cite{rosette}, and SyGuS~\cite{sygus}.

\subsection{\textsc{Sketch} and \textsc{Rosette}}
\textsc{Sketch}, developed by \citet{sketch}, is a pioneering work in the space of program synthesis frameworks.
It takes as input a partial program, i.e.
a program template with holes in place of desired subexpressions.
\textsc{Sketch} translates this template to SAT encoding, and applies counterexample-guided inductive synthesis to fill
in the holes with
expressions that satisfy the specification.

\textsc{Rosette} by \citet{rosette} is a DSL\hyp{}parameterized framework, which supports a rich suite of capabilities
including verification, synthesis, and repair.
Unlike \textsc{Sketch}, its input language is a limited subset of Racket programming language, which \textsc{Rosette}
translates to SMT constraints via symbolic execution.

Both \textsc{Sketch} and \textsc{Rosette} allow seamless translation of their input languages (custom C-like in
\textsc{Sketch} or limited Racket in \textsc{Rosette}) to SAT/SMT encoding at runtime.
It reduces the level of synthesis awareness required from the developer (\citeauthor{rosette} call this methodology
\emph{solver-aided programming}).
However, our experiments show that constraint-based techniques scale poorly to real-world industrial application
domains, which do not have a direct SMT theory~\cite{andersen:procedural,singh2012synthesizing}.
To enable program synthesis in such cases, PROSE separates domain-specific insights into \emph{witness
functions}, and uses a common deductive meta-algorithm in all application domains.
The resulting workflow is as transparent to the developer as solver-aided programming, but it does not require domain
axiomatization.

\subsection{Syntax-Guided Synthesis}
SyGuS~\cite{sygus} is a recent initiative that aims to (a) standardize the input specification language of program
synthesis problems;
(b) develop general-purpose synthesis algorithms for these problems, and
(c) establish an annual competition SyGuS-COMP of such algorithms on a standardized benchmark suite.
Currently, their input language is also based on SMT theories, which makes it inapplicable for complex industrial
domains (see \Cref{ch:intro}).
The main synthesis algorithms in SyGuS are enumerative search \cite{transit:protocols}, constraint-based search
\cite{bitvectors}, and stochastic search \cite{schkufza2013stochastic}.
Based on the SyGuS-COMP results, they handle different application domains best, although enumerative search is
generally effective on medium-sized problems in most settings.

\subsection{Deductive Synthesis}
The \emph{deductive} approach to program synthesis \cite{manna1980deductive} uses a formal system of deduction rules to
build a constructive definition of a program in a way that proves the program's validity.
This approach is efficient because at every point it works upon a partially correct program and never needs to eliminate
erroneous candidates (like enumerative search).
Its drawback is substantial manual effort to axiomatize the application domain into sound and complete deduction rules.

The deductive search of PROSE is an extension of the described ideas, where we reduce this effort by using local
deductive rules in the form of domain\hyp{}specific \emph{witness functions}.
They characterize the behavior of a \emph{single operator} on a \emph{single input}, whereas deduction rules
historically describe the behavior of \emph{partial programs} on \emph{all inputs}.
This allows synthesis designers to easily provide domain\hyp{}specific insight for program synthesis in complex DSLs.

\subsection{Type-Based Synthesis}

Type-based synthesis is another recent area in program synthesis research~\cite{popl16:frankle,polikarpova2016program}.
It defines a synthesis problem as a problem of \emph{finding a type inhabitant}, and uses the theory of refinement types
to resolve it.
A particularly attractive feature of type-based synthesis is that, similarly to PROSE, it uses
deductive reasoning, building the desired program \emph{top-down} from the specified properties.
The spec, expressed as a refinement on the program's output value type, can range from input-output
examples~\cite{popl16:frankle} to fully formalised properties~\cite{polikarpova2016program}, as long as these
refinements allow logical reasoning.
The prior work relies on \emph{liquid type inference}~\cite{rondon2008liquid} or conventional inference
rules~\cite{pldi15:osera} to perform such reasoning.

Program synthesis with refinement types is very effective in domains that enable logical reasoning on simple type
properties, such as data structures, functional programs, and security verification.
On these domains it significantly outperforms alternative solutions (constraint solving and enumeration), due to the
same feature that makes deduction efficient: it always operates on a partially correct program, filling in its holes by
deducing necessary properties (in this case, refinements) of these holes and applying the same inference recursively.
Similarly to constraint solves, applying this approach to data wrangling domains would require significant domain
axiomatization and development of a domain-specific reasoning engine, which is highly non-trivial for industrial
applications.

\subsection{Oracle-Guided Inductive Synthesis}
\citeauthor{ogis} recently developed a novel formalism for inductive synthesis called \emph{oracle-guided inductive
synthesis} (OGIS)~\cite{ogis}.
It unifies several commonly used approaches such as counterexample-guided inductive synthesis (CEGIS)~\cite{sketch} and
distinguishing inputs~\cite{bitvectors}.
In OGIS, an inductive learning engine is parameterized with a concept class (the set of possible programs), and it
learns a concept from the class that satisfies a given partial specification by issuing queries to a given oracle.
The oracle has access to the complete specification, and is parameterized with the types of queries it is able to
answer.
Queries and responses range over a finite set of types, including membership queries, witnesses, counterexamples,
verification queries, and distinguishing inputs.
They also present a theoretical analysis for the CEGIS learner variants, establishing relations between concept classes
recognizable by learners under various constraints.

The problem of interactive program synthesis, presented in this work, can be mapped to the OGIS formalism (with the end
user playing the role of an oracle).
Hence, any theoretical results established by \citeauthor{ogis} for CEGIS automatically hold for the settings of
interactive program synthesis where we only issue counterexample queries.

In addition, inspired by our study of mass-market deployment of PBE-based systems, we present further formalism for the
user's interaction with the synthesis system.
While the ``learner'' component in the OGIS formalism is limited to a pre-defined class of queries, our formalism adds a
separate modal ``hypothesizer'' component.
Its job is to analyze the current set of candidate programs and to ask the questions that best resolve the ambiguity
between programs in the set.
The hypothesizer is domain-specific, not learner-specific, and therefore can be refactored out of the learner and
reused with different synthesis strategies.

\section{Data Wrangling}

Various forms of data cleaning, parsing, and text manipulation have been addressed by the field of data mining.
Most system for discovering cleaning transformations on the data perform some form of \emph{active learning} by
combining intelligent search with human assistance.
Two prominent examples of this idea are Wrangler~\cite{wrangler} (later Trifacta\footnote{\url{https://trifacta.com}})
and DataXFormer~\cite{dataxformer}.

Both Wrangler and DataXFormer apply an algorithm similar to enumerative search in program synthesis to discover
transformations.
However, they significantly differ in their (a) search space, and (b) kind of specification from a human.

Wrangler employs a method coined \emph{predictive interaction}, where at each step in the session the system makes a
conjecture about an atomic transformation step that the user might want to apply on the dataset next.
To enable such interaction, their search space is a large loosely-connected DSL of standard atomic transformations.
In contrast, in PBE-based approaches the program being synthesized is an end-to-end sequence of multiple transformation
steps.
This makes the system much more accessible to end users (who do not necessarily understand an exact sequence of steps
that should be applied), but also increases the level of ambiguity, since the number of programs consistent with a given
set of input-output examples grows exponentially with program size.

DataXFormer builds transformations that combine together multiple data sources, such as web table or knowledge bases.
It does not have a pre-defined DSL of transformations, inferring them automatically.
In order to enable automatic inference of transformations (which may require domain-specific knowledge or table lookup),
DataXFormer involves a human at each step of the search process, presenting partial results and asking for
clarifications, additional transformation examples, and data filtering.
The key component of this system is \emph{table discovery}, which determines which data sources from a giant data lake
may be relevant to the given example-based query.
Since DataXFormer is interactive at every step, it can employ an EM-based ranking algorithm for resolving this
ambiguity~\cite{dataxformer}.
The confidence scores associated with each table are seeded with the number of examples it covers, and then iteratively
recomputed as DataXFormer changes its beliefs about relevance of each table and each data point to the answer.

\section{Active Learning}
In machine learning, \emph{active learning} is a subfield of semi-supervised learning where the learning algorithm is
permitted to issue queries to an oracle (usually a human)~\cite{al:settles}.
As applied to, e.g., classification problems, a typical query asks for a classification label on a new data point.
The goal is to achieve maximum classification accuracy with a minimum number of queries.

Research in active learning has focused on two important problems: (a) when to issue a query, and (b) how to pick a data
point for it.
For instance, in \emph{uncertainty sampling} \cite{lewis} an active learner queries the user on the input about which it
is least certain of the labeling.
The particular uncertainty measure varies by model.
A probabilistic model for learning a binary classifier could query about the input whose posterior probability is
closest to $0.5$ \cite{lewis}.
Other probabilistic classifiers use margin sampling \cite{marginSampling} or (like one of our suggested disambiguation
scores) the more general entropy approach.

This work borrows the ideas of active learning, extends them, and applies them in the domain of program synthesis.
In our setting, the issued queries do not necessarily ask for the exact output of the desired program on a given input
(an equivalent of ``label'' in ML), but may also ask for weaker output properties (e.g.
verify a candidate element of the output sequence).
In all cases, though, our queries are \emph{actionable}: they are convertible to constraints, which automatically
trigger a new iteration of synthesis.
We also develop a novel approach for picking an input for the query based on its \emph{disambiguation score} w.r.t.
the current set of candidate programs.
